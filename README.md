LLM_DAIGT

Open project for VLG 

In this primary notebook, I employed a Word2Vec vectorizer for word embedding. Subsequently, I experimented with numerous models, including Na√Øve Bayes and tree-based algorithms. Ultimately, I employed the CatBoost classifier, which yielded a ROC_AUC score of 0.677. Additionally, I attempted a voting ensemble-based classifier, which yielded a score of 0.713.

I went on to try a Bi-Directional LSTM-based model, and it received a score of 0.538.


Here is the link to the additional dataset I have used [https://www.kaggle.com/datasets/dsluciano/daigt-one-place-all-data](url)
